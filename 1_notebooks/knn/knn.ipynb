{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21403c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sktime.split import temporal_train_test_split\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e4cb2b",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe6f7719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: ../../0_data/bissau_merged.nc\n",
      "Rain threshold: 0.1 mm\n"
     ]
    }
   ],
   "source": [
    "# Data path\n",
    "DATA_PATH = Path(\"../../0_data/bissau_merged.nc\")\n",
    "\n",
    "# Center cell indices (for 5x5 grid)\n",
    "CENTER_LAT_IDX = 2\n",
    "CENTER_LON_IDX = 2\n",
    "\n",
    "# Rain threshold (mm)\n",
    "RAIN_THRESHOLD = 0.1\n",
    "\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Rain threshold: {RAIN_THRESHOLD} mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9146a365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (18263, 6)\n",
      "Date range: 1975-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "\n",
      "Basic statistics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                   t2m        d2m         tcc           sp   tp         rh\n",
       "datetime                                                                 \n",
       "1975-01-01  23.901215  14.001129   31.664080  1008.002686  0.0  53.899139\n",
       "1975-01-02  23.296295  21.144562   36.313396  1009.499207  0.0  87.722153\n",
       "1975-01-03  24.607361  20.040924    9.092018  1010.639160  0.0  75.744820\n",
       "1975-01-04  22.042206  18.102203    0.400352  1010.712708  0.0  78.363899\n",
       "1975-01-05  21.983063  20.208405  100.000015  1010.250916  0.0  89.676514\n",
       "...               ...        ...         ...          ...  ...        ...\n",
       "2024-12-27  23.750641  16.986481    1.199722  1011.753845  0.0  65.858002\n",
       "2024-12-28  23.277863  13.758942   15.811407  1011.230774  0.0  55.089417\n",
       "2024-12-29  22.382111  17.828278   88.618683  1011.127502  0.0  75.448097\n",
       "2024-12-30  22.167755  17.403229    0.000000  1010.276550  0.0  74.417450\n",
       "2024-12-31  21.788849  18.169098    0.000000  1011.097595  0.0  79.919800\n",
       "\n",
       "[18263 rows x 6 columns]>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load NetCDF4 with xarray\n",
    "ds = xr.open_dataset(DATA_PATH)\n",
    "\n",
    "# Convert timestamps to datetime\n",
    "time_values = pd.to_datetime(ds.valid_time.values)\n",
    "\n",
    "# Extract center cell data & apply unit conversions\n",
    "t2m_center = ds.t2m[:, CENTER_LAT_IDX, CENTER_LON_IDX].values - 273.15  # K → °C\n",
    "d2m_center = ds.d2m[:, CENTER_LAT_IDX, CENTER_LON_IDX].values - 273.15  # K → °C\n",
    "tcc_center = ds.tcc[:, CENTER_LAT_IDX, CENTER_LON_IDX].values * 100  # fraction → %\n",
    "sp_center = ds.sp[:, CENTER_LAT_IDX, CENTER_LON_IDX].values / 100  # Pa → hPa\n",
    "tp_center = ds.tp[:, CENTER_LAT_IDX, CENTER_LON_IDX].values * 1000  # m → mm\n",
    "\n",
    "# Create DataFrame with datetime index\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"datetime\": time_values,\n",
    "        \"t2m\": t2m_center,  # Temperature (°C)\n",
    "        \"d2m\": d2m_center,  # Dewpoint (°C)\n",
    "        \"tcc\": tcc_center,  # Cloud cover (%)\n",
    "        \"sp\": sp_center,  # Surface pressure (hPa)\n",
    "        \"tp\": tp_center,  # Precipitation (mm)\n",
    "    }\n",
    ")\n",
    "df.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "\n",
    "# Calculate Relative Humidity using Magnus formula\n",
    "def calc_relative_humidity(t2m, d2m):\n",
    "    a, b = 17.625, 243.04\n",
    "    rh = 100 * np.exp((a * d2m) / (b + d2m)) / np.exp((a * t2m) / (b + t2m))\n",
    "    return np.clip(rh, 0, 100)\n",
    "\n",
    "\n",
    "df[\"rh\"] = calc_relative_humidity(df[\"t2m\"].values, df[\"d2m\"].values)\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "print(f\"\\nBasic statistics:\")\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca2a68",
   "metadata": {},
   "source": [
    "## Create Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0604308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 8, 9, 10, 11, 12]\n",
      "[11, 12, 1]\n",
      "[12, 12, 0, 1, 2]\n",
      "                  t2m        d2m        tcc           sp        tp         rh\n",
      "datetime                                                                     \n",
      "1975-03-01  25.868011   9.681549  99.759598  1008.447327  0.000000  36.049957\n",
      "1975-03-02  23.366302  18.462555  65.093781  1009.395386  0.000000  73.969376\n",
      "1975-03-03  22.993988  20.936188  82.941643  1011.203308  0.000000  88.203934\n",
      "1975-03-04  22.538666  19.472076  28.746033  1010.579224  0.000000  82.826927\n",
      "1975-03-05  22.709015  18.705963  45.916401  1009.494629  0.000000  78.151817\n",
      "...               ...        ...        ...          ...       ...        ...\n",
      "2024-05-27  27.469025  24.173981  20.968996  1011.241394  0.000000  82.261566\n",
      "2024-05-28  27.548096  24.892395  97.372612  1013.597595  0.006865  85.478035\n",
      "2024-05-29  25.724091  23.913544  98.947441  1014.854675  0.015840  89.754143\n",
      "2024-05-30  28.496033  24.027252  97.439369  1013.135010  0.000000  76.799973\n",
      "2024-05-31  27.463348  22.936188  51.229275  1010.603516  0.000000  76.373360\n",
      "\n",
      "[4600 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_timeframe(df, month, window_size=1):\n",
    "    \"\"\"\n",
    "    Retrieves the same time period from all years present in the df.\n",
    "    Use this to avoid searching similar days which are in completely different seasons.\n",
    "    df: The historical dataframe \n",
    "    month: The target month to query\n",
    "    window_size: How many months each side of the target month to search for\n",
    "    \"\"\"\n",
    "    valid_months = range(month- window_size, month + window_size + 1)\n",
    "    # Handle wrap-around for Jan/Dec\n",
    "    valid_months = [m if m >= 0 else 12 for m in valid_months] \n",
    "    valid_months = [m if m <= 12 else 1 for m in valid_months]\n",
    "\n",
    "    if df is None:\n",
    "        return valid_months\n",
    "\n",
    "    return df[df.index.month.isin(valid_months)]    \n",
    "\n",
    "print(get_timeframe(None, 9, 3))\n",
    "print(get_timeframe(None, 12, 1))\n",
    "print(get_timeframe(None, 0, 2))\n",
    "\n",
    "print(get_timeframe(df, 4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d18891f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target days:                    t2m        d2m         tcc           sp   tp         rh\n",
      "datetime                                                                 \n",
      "1975-01-01  23.901215  14.001129   31.664080  1008.002686  0.0  53.899139\n",
      "1975-01-02  23.296295  21.144562   36.313396  1009.499207  0.0  87.722153\n",
      "1975-01-03  24.607361  20.040924    9.092018  1010.639160  0.0  75.744820\n",
      "1975-01-04  22.042206  18.102203    0.400352  1010.712708  0.0  78.363899\n",
      "1975-01-05  21.983063  20.208405  100.000015  1010.250916  0.0  89.676514\n",
      "1975-01-06  22.323212  20.448883    7.034683  1010.767029  0.0  89.151909\n",
      "1975-01-07  21.732574  18.764679    0.559998  1012.075684  0.0  83.243317\n",
      "--- Top 5 Similar Historical Periods ---\n",
      "datetime\n",
      "1975-01-07     0.000000\n",
      "2019-05-12    36.506321\n",
      "1981-04-20    42.278000\n",
      "1998-05-31    43.709774\n",
      "1993-04-12    44.558174\n",
      "Name: similarity_score, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_knn(df, target_pattern_df, k=5):\n",
    "    \"\"\"\n",
    "    Finds historical periods that match the pattern of multiple columns.\n",
    "    df: The historical dataframe (cols: Rainfall, Humidity, Temp, etc)\n",
    "    target_pattern_df: The x-day dataframe of the current situation\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Align Data Types\n",
    "    # Ensure we are only comparing numbers (floats), no dates/strings\n",
    "    df_numeric = df.select_dtypes(include=[np.number])\n",
    "    target_numeric = target_pattern_df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # 2. Prepare Numpy Arrays\n",
    "    history = df_numeric.values  # Shape: (Total_Days, N_Cols)\n",
    "    target = target_numeric.values # Shape: (7, N_Cols)\n",
    "    \n",
    "    window_len = len(target)\n",
    "    n_features = history.shape[1]\n",
    "    \n",
    "    # 3. Create the \"3D View\" of History (Instant, no loops)\n",
    "    # This creates a virtual view of shape: (Rows, 1, Window_Size, N_Features)\n",
    "    windows = np.lib.stride_tricks.sliding_window_view(\n",
    "        history, \n",
    "        window_shape=(window_len, n_features)\n",
    "    )\n",
    "    \n",
    "    # Squeeze to get Shape: (Rows, Window_Size, N_Features)\n",
    "    #windows = windows.squeeze()\n",
    "    windows = windows[:, 0, :, :]\n",
    "    \n",
    "    # 4. Calculate MSE (Euclidean Distance)\n",
    "    # (History_Window - Target_Window)^2\n",
    "    # We sum errors across the Window (axis 1) and Features (axis 2)\n",
    "    diff = windows - target\n",
    "    mse = np.mean(diff ** 2, axis=(1, 2))\n",
    "    \n",
    "    # 5. Map results back to Dates\n",
    "    # The 'mse' array is shorter than the df by (window_len - 1)\n",
    "    # We use the index corresponding to the END of each window\n",
    "    result_index = df.index[window_len-1:]\n",
    "    \n",
    "    results = pd.Series(mse, index=result_index, name='similarity_score')\n",
    "    \n",
    "    return results.nsmallest(k)\n",
    "\n",
    "# --- USAGE ---\n",
    "# 1. Define your target (e.g., the first 7 days of the dataset)\n",
    "target_days = df.iloc[0:7] \n",
    "\n",
    "# 2. Run the search\n",
    "# It automatically compares Rainfall vs Rainfall, Humidity vs Humidity, etc.\n",
    "best_matches = get_knn(df.copy(), target_days)\n",
    "\n",
    "print(\"Target days: \", target_days)\n",
    "\n",
    "print(\"--- Top 5 Similar Historical Periods ---\")\n",
    "print(best_matches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e30b5",
   "metadata": {},
   "source": [
    "## Generate Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05889c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t2m</th>\n",
       "      <th>d2m</th>\n",
       "      <th>tcc</th>\n",
       "      <th>sp</th>\n",
       "      <th>rh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1976-01-16</th>\n",
       "      <td>23.344452</td>\n",
       "      <td>9.829498</td>\n",
       "      <td>3.069782</td>\n",
       "      <td>1011.577820</td>\n",
       "      <td>42.339874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976-01-17</th>\n",
       "      <td>22.269806</td>\n",
       "      <td>7.887360</td>\n",
       "      <td>99.118134</td>\n",
       "      <td>1011.335571</td>\n",
       "      <td>39.636539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976-01-18</th>\n",
       "      <td>21.866119</td>\n",
       "      <td>7.746979</td>\n",
       "      <td>100.000015</td>\n",
       "      <td>1009.373047</td>\n",
       "      <td>40.237514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976-01-19</th>\n",
       "      <td>19.794952</td>\n",
       "      <td>13.104645</td>\n",
       "      <td>94.595528</td>\n",
       "      <td>1008.343506</td>\n",
       "      <td>65.332451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976-01-20</th>\n",
       "      <td>21.123810</td>\n",
       "      <td>16.276764</td>\n",
       "      <td>31.339640</td>\n",
       "      <td>1010.161865</td>\n",
       "      <td>73.852829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-21</th>\n",
       "      <td>23.705719</td>\n",
       "      <td>20.141388</td>\n",
       "      <td>97.974464</td>\n",
       "      <td>1009.564697</td>\n",
       "      <td>80.453857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-22</th>\n",
       "      <td>24.855560</td>\n",
       "      <td>18.866119</td>\n",
       "      <td>96.625290</td>\n",
       "      <td>1011.302246</td>\n",
       "      <td>69.373589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-23</th>\n",
       "      <td>24.614746</td>\n",
       "      <td>18.754425</td>\n",
       "      <td>92.453003</td>\n",
       "      <td>1011.209290</td>\n",
       "      <td>69.889435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-24</th>\n",
       "      <td>26.090424</td>\n",
       "      <td>15.257477</td>\n",
       "      <td>39.908485</td>\n",
       "      <td>1010.886475</td>\n",
       "      <td>51.297428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-25</th>\n",
       "      <td>25.891693</td>\n",
       "      <td>15.162018</td>\n",
       "      <td>93.680206</td>\n",
       "      <td>1010.586731</td>\n",
       "      <td>51.587063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16081 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  t2m        d2m         tcc           sp         rh\n",
       "datetime                                                            \n",
       "1976-01-16  23.344452   9.829498    3.069782  1011.577820  42.339874\n",
       "1976-01-17  22.269806   7.887360   99.118134  1011.335571  39.636539\n",
       "1976-01-18  21.866119   7.746979  100.000015  1009.373047  40.237514\n",
       "1976-01-19  19.794952  13.104645   94.595528  1008.343506  65.332451\n",
       "1976-01-20  21.123810  16.276764   31.339640  1010.161865  73.852829\n",
       "...               ...        ...         ...          ...        ...\n",
       "2020-01-21  23.705719  20.141388   97.974464  1009.564697  80.453857\n",
       "2020-01-22  24.855560  18.866119   96.625290  1011.302246  69.373589\n",
       "2020-01-23  24.614746  18.754425   92.453003  1011.209290  69.889435\n",
       "2020-01-24  26.090424  15.257477   39.908485  1010.886475  51.297428\n",
       "2020-01-25  25.891693  15.162018   93.680206  1010.586731  51.587063\n",
       "\n",
       "[16081 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame()\n",
    "y[\"rain_binary\"] = (df[\"tp\"] > RAIN_THRESHOLD).astype(int)\n",
    "df = df.drop(columns=['tp'])\n",
    "\n",
    "X_train = df.loc[\"1976-01-16\": \"2020-01-25\"]\n",
    "y_train =y.loc[\"1976-01-16\": \"2020-01-25\"]\n",
    "\n",
    "X_test = df.loc[\"2020-01-26\": \"2024-12-17\"]\n",
    "y_test = y.loc[\"2020-01-26\": \"2024-12-17\"]\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69608209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabililty_score = lambda array: np.sum(array)/len(array)\n",
    "majority_score = lambda array: np.bincount(array).argmax()\n",
    "\n",
    "\n",
    "def get_prediction(x, X_train, y_train, score_function):\n",
    "    valid_months = get_timeframe(X_train, x.index.month[0])\n",
    "    best_matches = get_knn(valid_months, x)\n",
    "    rainy_days = y_train.loc[best_matches.index.to_list()][\"rain_binary\"].to_list()\n",
    "    \n",
    "    return score_function(rainy_days)\n",
    "\n",
    "get_prediction(X_test.iloc[0:1], X_train, y_train, probabililty_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a878bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.8920581655480985\n",
      "F1 score is  0.4469914040114613\n",
      "ROC AUC is  0.8226391737391363\n"
     ]
    }
   ],
   "source": [
    "# Single day compared to training set\n",
    "y_test_pred = X_test.apply(lambda x: get_prediction(x.to_frame().T, X_train, y_train, majority_score), axis=1)\n",
    "y_test_prob = X_test.apply(lambda x: get_prediction(x.to_frame().T, X_train, y_train, probabililty_score), axis=1)\n",
    "\n",
    "\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "print(\"Accuracy is \", test_acc)\n",
    "print(\"F1 score is \", test_f1)\n",
    "print(\"ROC AUC is \", test_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b597099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions complete.\n",
      "Accuracy is  0.8831096196868009\n",
      "F1 score is  0.43360433604336046\n",
      "ROC AUC is  0.8535545533862872\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Prepare \"Context Data\"\n",
    "# We attach the last 7 days of X_train to the START of X_test.\n",
    "# This ensures the very first row of X_test has a valid 7-day history window.\n",
    "# Min value is 1\n",
    "window_size = 7\n",
    "\n",
    "# We only need (window_size - 1) past days to complete the first window.\n",
    "if window_size > 1:\n",
    "    # Take the last (N-1) rows from training\n",
    "    history_padding = X_train.iloc[-(window_size - 1):]\n",
    "    context_data = pd.concat([history_padding, X_test])\n",
    "else:\n",
    "    # If window is 1, we don't need any history from Train\n",
    "    context_data = X_test\n",
    "\n",
    "predictions = []\n",
    "predictions_prob = []\n",
    "\n",
    "\n",
    "# 2. Iterate strictly over the X_test portion\n",
    "for i in range(len(X_test)):\n",
    "    \n",
    "    # The 'end' of our window is the current step in the test set\n",
    "    # The 'start' is shifted back by window_size\n",
    "    # We add 'window_size' to i because we padded the start of the array\n",
    "    end_idx = i + window_size\n",
    "    start_idx = i \n",
    "    \n",
    "    # Extract the 7-day window ending just before the target day\n",
    "    # (Or including it, depending on your specific logic)\n",
    "    current_window = context_data.iloc[start_idx : end_idx]\n",
    "    \n",
    "    # Make the prediction by passing through the window\n",
    "    pred = get_prediction(current_window, X_train, y_train, majority_score)\n",
    "    predictions.append(pred)\n",
    "\n",
    "    pred_prob = get_prediction(current_window, X_train, y_train, probabililty_score)\n",
    "    predictions_prob.append(pred_prob)\n",
    "\n",
    "# 3. Create Result Series\n",
    "y_test_pred = pd.Series(predictions, index=X_test.index)\n",
    "y_test_prob = pd.Series(predictions_prob, index=X_test.index)\n",
    "\n",
    "\n",
    "print(\"Predictions complete.\")\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_prob)\n",
    "print(\"Accuracy is\", test_acc)\n",
    "print(\"F1 score is\", test_f1)\n",
    "print(\"ROC AUC is\", test_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65675cfd",
   "metadata": {},
   "source": [
    "1 day window:\n",
    "Predictions complete.\n",
    "Accuracy is  0.8920581655480985\n",
    "F1 score is  0.4469914040114613\n",
    "ROC AUC is  0.8226391737391363\n",
    "\n",
    "3 day window:\n",
    "Predictions complete.\n",
    "Accuracy is  0.8853467561521253\n",
    "F1 score is  0.43526170798898073\n",
    "ROC AUC is  0.8457077946358764\n",
    "\n",
    "7 day window: \n",
    "Predictions complete.\n",
    "Accuracy is  0.8831096196868009\n",
    "F1 score is  0.43360433604336046\n",
    "ROC AUC is  0.8535545533862872"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-leo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
